# GAN to Discrete Event Simulator for MIDI Music Generation

Training of two GAN models on MIDI music data for the task of automated music composition. 

### Overview
1. [Requirements](#requirements)
2. [Demo](demo.ipynb)
2. [Folder Structure](#folder-structure)

# Requirements

## [requirements.txt](requirements.txt)

``pip install -r requirements.txt``

## [FluidSynth](https://www.fluidsynth.org/download/)

Install FluidSynth from the linked website. On Windows, FluidSynth has to be installed by using [Chocolatey](https://chocolatey.org/)
uing the following command:

``choco install fluidsynth``

Make sure that the path is stored in the system `PATH` variable and that the sound font file `FluidR3_GM.sf2` is present 
in each folder that you use FluidSynth in. 

FluidSynth is used to synthesize music from the generated MIDI files. We only use it for training the first model of the project (GAN-DES).

# [Demo](demo.ipynb)

Explore this Jupyter Notebook, for getting a quick overview of what models can be trained and how, as well as listening 
to some of their output.

# Folder Structure

## [Data](data)

This folder contains the data used for training. In our case, we trained on the [MAESTRO](https://magenta.tensorflow.org/datasets/maestro), which we stored in this folder. 
It is a dataset containing MIDI files with a size of 81 MB. The data contains 200 hours of virtuosic piano playing.

## [GAN DES](GAN_DES)

This folder contains the code to train and execute the Generative Adversial Network (GAN) to Discrete Event Simulator (DES).

### [adj_sim_outputs](GAN_DES/adj_sim_outputs)

The output files created during model training or when using the DES to generate music. Each format is stored, MIDI, spectrogram (.png), and audio (.wav).

### [logs](GAN_DES/logs)

The log file [simulation.log](GAN_DES/logs/simulation.log) is created by the DES and then used to generate the music.

### [models](GAN_DES/models)

Folder where the model files are stored during training. 

### [datasets](GAN_DES/datasets.py)

This python script contains the PyTorch Datasets for training on one song and training on the MAESTRO dataset. If you would
like to train on your own data, the data needs to be stored and loaded by implementing your own [PyTorch Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).

### [matrix_sim_process](GAN_DES/matrix_sim_process.py)

This python script contains the ``matrix_to_wav()`` function, which is used to convert the matrix generated by the generator
model to an audio wave. Then, this audio wave is converted to its spectrogram representation. 

### [sim_log_process_music.py](GAN_DES/sim_log_process_music.py)

This python file contains the ``process_adjsim_log()`` function, which is used by the ``matrix_to_wav()`` function for
generating music from the output of the DES.

### [SIMNN](GAN_DES/SIMNN.py)

This python script is used for training the GAN DES model. It contains the generator and discriminator models definitions, 
as well as the training hyperparameters. By running this script, the GAN DES model is trained.

### [simulation_v3](GAN_DES/simulation_v3.py)

Contains the actual DES. Is used by the function ``matrix_to_wav()`` to perform the simulation, after receiving the matrix
generated by the GAN generator. 

### [util](GAN_DES/util.py)

Contains different functions for creating the Mel Spectrogram and slicing audio.

## [MM GAN DES](MMGAN_MIDI_DES/network_tests.py) 

Code for training and using the multi-modal GAN (MM-GAN) with Discrete Event Simulator (DES).

This python script is used for training the MM-GAN DES model. It contains the generator, second beat generator 
and discriminator models definitions, as well as the training hyperparameters. 
By running this script, the MM-GAN DES model is trained. 

### [adj_sim_outputs](MMGAN_MIDI_DES//adj_sim_outputs)

The output files created during model training or when using the DES to generate music. The MIDI format is stored.

### [models](MMGAN_MIDI_DES//models)

Folder where the model files are stored during training. 

### [datasets](MMGAN_MIDI_DES/datasets.py)

This python script contains the PyTorch Datasets for training on the MAESTRO dataset, by pickling it and accessing it later for faster training.
It also contains the function ``generate_piano_roll()``, which generates piano rolls from MIDI data input. If you would
like to train on your own data, the data needs to be stored and loaded by implementing your own [PyTorch Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).

### [matrix_sim_process](MMGAN_MIDI_DES/matrix_sim_process.py)

This python script contains the ``matrix_to_midi()`` function, which is used to convert the matrix generated by the generator
model to a MIDI file directly.

### [sim_log_to_midi.py](MMGAN_MIDI_DES/sim_log_to_midi.py)

This python file contains the ``process_adjsim_log()`` function, which is used by the ``matrix_to_midi()`` function for
generating MIDI output from the output of the DES.

### [simulation_v3](MMGAN_MIDI_DES/simulation_v3.py)

Contains the actual DES. Is used by the function ``matrix_to_midi()`` to perform the simulation, after receiving the matrix
generated by the GAN generator. 

### [util](MMGAN_MIDI_DES/util.py)

Contains different functions for creating the Mel Spectrogram and slicing audio.
